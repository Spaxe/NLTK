# Natural Language Processing Toolkit with IPython

Currently converting from Python2 to Python3

<br>
<img style="float:left" src="http://ipython.org/_static/IPy_header.png" />
<br><br><br>

This is a basic overview of the ResBaz NLTK sessions. It provides an overview of the main things being taught in the stream, as well as some links to additional resources.

All the materials we're using in class are in this repository. In fact, cloning this repository will be our first activity together as a group!

# Session 1: Orientation

In this session, you will learn how to use IPython Notebooks, as well as how to complete basic tasks with Python/NLTK.

* Getting up and running
* What exactly are *Python*, *IPython* and *NLTK*?
* Introductions to *IPython Notebook*
* Overview of basic Python concepts: *significant whitespace*, *input/output types*, *commands and arguments*, etc.
* Introduction to NLTK
* Quickstart: *US Inaugural Addresses Corpus*
*  Plot key terms in the inaugural addresses longitudinally
* Discussion: *Why might we want to use NLTK? What are its limitations?*

# Session 2: Functions, lists and variables

In this session, we devote more time to the fundamentals of Python, learning how to create and manipulate different kinds of data. So that you can use NLTK with confidence, we devote much of the session to:

* Working with variables
* Writing functions
* Creating frequency distributions

# Session 3: Common NLTK tasks

We've now got a basic understanding of Python. There's still a lot more to learn, though! This final session on the first day of ResBaz involves using the skills we've already learned to perform common kinds of analysis on real data. Key tasks covered are:

* Overview of common tasks, and why we need them
* Using our own data (from web and from disk)
* Searching with [Regular Expressions](http://www.regular-expressions.info/) and then by NLTK stemmer
* Sentence splitting: trivial or not?
* Tokenisation: defining a word and operationalising this definition
* Keywording
* Clustering/n-gramming
* Collocation
* Concordancing

# Session 4: The Fraser Corpus

By Day Two, we're familiar with what NLTK is and how to use it. It's time to put it to work on a novel dataset. We've chosen a [corpus of Malcolm Fraser's speeches](http://www.unimelb.edu.au/malcolmfraser/speeches/electorate/). In this session, we:

* Introduce the corpus
* Explore metadata
* Data structuring by metadata feature
* Keywords, n-grams, and collocates in the Fraser Corpus
* POS tagging and parsing raw data

# Session 5: Charting change in Fraser's speeches

In this session, we're going to use some purpose-built tools to look for longitudinal changes in the language of Malcolm Fraser's speeches. We hope to cover the functionality of tools quickly, so that everyone has time to use the tools to investigate anything that interests them in the corpus.

* Introduction to some purpose-built functions
* Searching syntax trees
* Interrogating each subcorpus
* Visualising results
* Viewing and editing results
* Using functional grammar to understand interpersonal and experiential meanings in the corpus
* Free interrogation and plotting of the corpus

# Session 6: Getting the most out of what we've learned

So, we've learned some great skills! But, we need to know how to put these skills into practice within our own work. Using the Fraser Speech Corpus data and our findings, we'll conclude the stream by focussing on:

* Storing your data and results
* Using what youâ€™ve learned here
* Developing your skills further
* Summarising and saying goodbye

# Additional resources

Here are some links that may come in handy if you want more information about what the NLTK stream is all about.

* [IPython homepage](http://ipython.org/): local machine installation, documentation, add-ons
* [NLTK homepage](http://www.nltk.org/): much of what is covered in this stream is also available in the NLTK Book, which is available both online and in print
* [Figshare](http://figshare.com/): for uploading your raw findings
* [GitHub](https://github.com): a home for you code, with version control
* [ResBaz materials on GitHub](https://github.com/resbaz): where all the open-source ResBaz materials can be found, including the IPython Notebooks and functions for turning them into .py, .tex, .html or .md files
* [Stack Overflow](http://stackoverflow.com/): many common Python/IPython/NLTK/Regex/Shell questions and answers can be found here.
